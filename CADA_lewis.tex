\documentclass[man, noapacite, 12pt]{apa2}

\makeatletter
\newenvironment{chapquote}[2][2em]
  {\setlength{\@tempdima}{#1}%
   \def\chapquote@author{#2}%
   \parshape 1 \@tempdima \dimexpr\textwidth-2\@tempdima\relax%
   \itshape}
  {\par\normalfont\hfill--\ \chapquote@author\hspace*{\@tempdima}\par\bigskip}
\makeatother

%\usepackage{pdfsync}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{apacite2}
\usepackage{fullpage,rotating}
\usepackage{pslatex}
\usepackage{amssymb}
\usepackage{multirow}


\title{Linguistic structure emerges from cognitive mechanisms}
\author{Molly L. Lewis}
\affiliation{Department of Psychology, Stanford University\\ Conceptual Analysis of Dissertation Area\\ 6 October 2014}

\shorttitle{Linguistic structure emerges from cognitive mechanisms}
\rightheader{Linguistic structure emerges from cognitive mechanisms}
\acknowledgements{Advisor: Michael C. Frank\\ \noindent Additional Readers: Ellen Markman and Noah Goodman}

\abstract{Language is highly structured --- from the way meaning is organized into categories to elaborate regularities in grammar. Where does this structure come from? In this paper, I argue that linguistic structure is causally related to linguistic usage.  In Part I, I begin by suggesting that language use is a kind of  coordination problem and that Horn's taxonomy of pragmatic pressures (1984) provides a useful framework for understanding this problem in the case of language. I then highlight a number of phenomena in linguistic usage that are reflected in linguistic structure. In Part II, I try to outline the causal processes that leads to this similarity between usage and structure. This analysis relies on a division of language into five different timescales: pragmatic, discourse, developmental, cultural, and evolution. I conclude by surveying a range of cognitive phenomena at each timescale.}


%\abstract{People interact with people and, because of shared interest, try to coordinate their behavior. This behavior is governed by the competition of pragmatic pressures. These pressures lead to equilibria. These equilibria become conventionalized over time (Lewis). This convention becomes an additional pressure in the moment of interaction. Language as a paradigm case of these dynamics.}

\begin{document}
\maketitle

%%%%%%%%% INTRO %%%%%%%%% 
%\begin{chapquote}{Aristotle, \textit{Nic. Ethics II 6}}
%\noindent  Virtue, then, is a state of character concerned with choice, lying in a mean, i.e. the mean relative to us, this being determined by a rational principle, and by that principle by which the man of practical wisdom would determine it. Now it is a mean between two vices, that which depends on excess and that which depends on defect; and again it is a mean because the vices respectively fall short of or exceed what is right in both passions and actions, while virtue both finds and chooses that which is intermediate. Hence in respect of its substance and the definition which states its essence virtue is a mean, with regard to what is best and right an extreme.
%\end{chapquote}

\begin{chapquote}{G.K. Zipf, \textit{1949}}
\noindent  Human society can be viewed as a field which both influences the individual members of the group and is influenced by them. 
\end{chapquote}

\section{Introduction}
``Room for cream?'' asked the barista. ``Mm, yes -- just a bit" replied the customer. Mundane linguistic interactions such as this are the building blocks of daily experience. They are individuals making sounds to each other in an effort to coordinate their behavior in the physical world \cite{clark2006social}. These interactions are messy, variable, and highly unconstrained. Indeed it is this variability that gives language its vast expressive power \cite{hockett1960}. Yet, despite this appearance of irregularity, rich patterns in linguistic usage are revealed when we aggregate across instances of language use both within and across languages. At the level of syntax, for example, there is a strong bias in English to put subjects before verbs and, across languages, this pattern is attested more often than would be expected by chance alone  \cite{dryer2005order}. These types of probabilistic regularities exist at every level of linguistic structure --- from phonology, to semantics, syntax, and discourse --- and researchers from a variety of disciplines have taken as their project the goal of characterizing these regularities.

In this paper, I argue that we can gain  insight into the character of linguistic structure by considering the dynamics of language use. I will suggest the best way to do this is by framing language use as an instance of a broader phenomenon: social interaction \cite{clark1996using}. In particular, I will adopt the formal framework of social interaction proposed by \citeA{schelling1980strategy} in which social interactions are viewed as acts of solving coordination problems.  To illustrate, consider the barista example above. In this example, the agents are the barista and the customer, and they must coordinate how  to fill the coffee mug. There are two outcomes --- full and almost full --- and the barista's desired outcome is determined by the preference of the customer. In this case, the barista and the customer rely on language to coordinate their behavior, but this coordination could have been achieved in other ways (e.g. the customer could have shook her head, pointed to the place inside the mug that she wanted the coffee filled to, etc.). Coordination of their behavior is achieved  by arriving at the mutually preferred outcome (the customer's mug is almost full).

A key tenet to the broader argument is that the act of using language is itself an act of solving a coordination problem \cite{clark1996using}. When a person speaks, there are many possible ways the utterance could be interpreted, and arriving at the intended interpretation is an act of coordination. For example, in the case of the customer's interaction with the barista, there are many possible interpretations of the phrase, ``Room for cream?." The barista could mean ``Would you like to add cream to your coffee? If so, I will facilitate that by not filling your mug full with coffee." Or, ``We have so much extra inventory of cream! Do you have room in your bag to take some?" Or, ``Do you like the band `Room for cream'?". Or, if the speaker is speaking another language, a totally unrelated meaning. The point is that the speaker's intended meaning is underspecified from the language alone and the interlocutors must work collaboratively to arrive at a shared understanding. Following \citeA{lewis1969convention}, I will suggest that we can gain insight into the dynamics of linguistic coordination problems by using Schelling's formal framework.  This perspective on language use will ultimately provide a helpful framework for understanding the relationship between language use and language structure.

It is worth reflecting on the historical relationship between these two aspects of language. Across many schools of linguistics, theorists have made a theoretical cut between language use and language structure: {\it parole} vs.\  {\it langue}  \cite{saussure},  {\it token}  vs.\  {\it type}  \cite{peirce}, and  {\it performance}  vs.\  {\it competence}  \cite{chomsky1965aspects}. These theorists  have different views on the ontological status of structure --- Saussure suggests it is a social fact, while Chomsky argues it is fundamentally a cognitive phenomenon --- but they nonetheless agree that there is some sort of invariance in language and it should be the focus of study. Language use has often been seen as an irregular, variant, and epiphenomenal to the true subject of study: structure. However, a number of more recent movements have begun to focus on language use. \nocite{labov197213} Labov's (1972) work was an important challenge to exclusionary focus on abstract structure. His work revealed systematicity in the variation of phonology as function of social variables, suggesting that ``messy" language use was governed by regularities and could therefore be studied scientifically. The study of pragmatics, more generally, can be seen as a step to find regularity in language use. The goal of this paper is to suggest that, not only are these two aspects of language deeply related to each other, but that the key to understanding linguistic structure may lie in understanding linguistic use.

In Part I, I will outline the linguistic coordination problem as a paradigmatic case of the social coordination problem. I will suggest that coordination problems are solved through the dynamics of two opposing two forces --- the goals of the speaker and the hearer. Following Lewis, I suggest that these opposing forces are resolved by finding an equilibrium point. I will then argue that the equilibria that are reached in language use are reflected in the structure of language, and survey a variety of phenomena in linguistic structure that show this pattern.

In Part II, I will consider the mechanism that might cause linguistic structure to reflect the equilibria reached in linguistic use. Lewis argued that once individuals succeed in solving a coordination problem, there is a tendency to stick with that solution (even though other, equally good solutions exist). This solution is called a convention. I will argue that the key to understanding the link between regularities in linguistic usage and linguistic structure is the process of children's acquisition of these conventions. I will consider how the dynamics of language acquisition might lead to language change. Finally, I will consider the complementary role of conventions and cognitive forces in solving language coordination problems, and the  empirical challenge associated with disentangling the two.

%%%%%%%%% PART I %%%%%%%%% 
\section{Part I: Linguistic structure reflects pragmatic equilibria}

Where does linguistic structure come from? \citeA[2010]{christiansen2008} propose a compelling theory. They argue that  multiple cognitive constraints dynamically influence language evolution. They suggest four constraints: the representational format of thought, properties of the percepto-motor system, learning and processing constraints, and constraints that result from reasoning about others intentions ({\it pragmatic} constraints). Their argument is that these  cognitive constraints  influence  language at the moment of use, but over time, these biases become instantiated in the structure of language. Although each of these constraints likely plays an important role in the evolution of language, the present paper focuses on the independent contribution of pragmatic constraints. The claim is that pragmatic constraints that play out at the moment of language use become fossilized in the structure of language over time. To develop this claim, we begin by modeling language use as a type of social coordination. We then turn to an analysis of language use as a social coordination problem. Finally, we consider three cases where there are similarities in phenomena between language use and language structure.

\subsection{Social interaction as a coordination problem}
Many theorists of language \cite{zipf1936, lewis1969convention, grice1975logic, clark1996using} have observed that language is an instance of a much broader class of behavioral phenomena --- social coordination. For each, language use is a case of multiple agents making interdependent  rational choices.\footnote{In outlining his seminal theory of pragmatics, Grice  writes: ``As one of my avowed aims is to see talking as a special case or variety of purposive, indeed rational, behavior, it may be worth noting that the specific expectations of presumptions connected with at least some of the foregoing maxims have their analogues in the sphere of transactions that are not talk exchanges" \cite[pg. 47]{grice1975logic}.} By adopting work from game theory,  \citeA{lewis1969convention} formalized the notion of language as a coordination problem. He defines a  {\it coordination problem} as follows: \begin{quote} Two or more agents must each choose one of several alternative actions. Often all the agents have the same set of alternative actions, but that is not necessary. The outcomes the agents want to produce or prevent are determined jointly by the actions of all the agents (p. 8).
\end{quote} 
The key feature of these problems is that some combinations of the agents' choices are better than others: there are a set of joint choices in which no agent would have a larger payoff had the agent alone changed her choice. We refer to these as {\it equilibrium points}. 

This broad framing can describe the dynamics of many social interactions. Take the above case of the barista and the customer, for example. We can model this interaction using a payoff matrix (Table 1). In the matrix, we represent the customer's payoff along the rows and the barista's payoff along the columns. There are two possible choices for  level of coffee in the cup---  full and  almost full --- and so each agent gets two rows or columns. 
\begin{table}[t]
\begin{center}
\begin{tabular}{l p{3cm} l p{3cm} l p{3cm} r}
 &  & \multicolumn{2}{c}{customer} \\ \cline{2-4} 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{full} & \multicolumn{1}{l|}{almost full} \\ \cline{2-4} 
\multicolumn{1}{c|}{\multirow{2}{*}{barista}} & \multicolumn{1}{l|}{full} & \multicolumn{1}{l|}{0,0} & \multicolumn{1}{l|}{0,0} \\ \cline{2-4} 
\multicolumn{1}{c|}{} & \multicolumn{1}{l|}{almost full} & \multicolumn{1}{l|}{0,0} & \multicolumn{1}{l|}{1,1} \\ \cline{2-4} 
\end{tabular}
\caption{A payoff matrix of a context of a simple interaction --- a barista trying to determine how full to fill a customers' cup. Given the customer's preference for cream, there lies an equilibrium point at `almost full' for both barista and customer. To arrive at this equilibrium point, the two must coordinate.}
\end{center}
\end{table}
The agents relative payoffs are indicated in the cells, with the barista's on the left, and the customer's on the right. This happens to be a very simple equilibria --- there is one, and only one, possible set of actions in which is an equilibrium. The customer prefers almost full and the barista fills the cup to almost full. The problem is that the barista does not know a priori where this equilibrium lies, i.e. that the customer's pay off for almost full is 1, relative to 0 for full. To solve this coordination problem, the customer and barista make use of language.

More complicated coordination problems arise when there are multiple possible equilibria. Consider a weekend trip in which food and alcohol must be brought. To distribute the burden, half of the vacationers will bring food and the other half alcohol. In this case, the pay off matrix might look something like Table 2. Neither group --- Group A or B --- has a strong preference about which of the two commodities each brings. However, what is important is that one group brings food and the other alcohol (no one will be happy on a weekend trip with only food or only alcohol). There are thus two equilibria, one  at each set of choices where the two groups bring different things. By chance, the vacationers are equally likely to end up in a non-equilibrium as they are an equilibria. They must  therefore coordinate, via language or some other means, to ensure that they end up at an equilibrium.

\begin{table}[t]
\begin{center}
\begin{tabular}{l p{3cm} l p{3cm} l p{3cm} l}
 &  & \multicolumn{2}{c}{Group A} \\ \cline{2-4} 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{food} & \multicolumn{1}{l|}{alcohol} \\ \cline{2-4} 
\multicolumn{1}{c|}{\multirow{2}{*}{Group B}} & \multicolumn{1}{l|}{food} & \multicolumn{1}{l|}{0,0} & \multicolumn{1}{l|}{1,1} \\ \cline{2-4} 
\multicolumn{1}{c|}{} & \multicolumn{1}{l|}{alcohol} & \multicolumn{1}{l|}{1,1} & \multicolumn{1}{l|}{0,0} \\ \cline{2-4} 
\end{tabular}
\caption{A payoff matrix for a social interaction in which there are two equilibria. Neither group cares who brings what commodity on the vacation; they only care that they bring different things. }
\end{center}
\end{table}

What are the psychological forces that support these coordination games? Zipf's theory of human behavior (1949) provides  insight. He argued that all human behavior could be accounted for by a single principle: people are motivated to minimize their effort ({\it The Principle of Least Effort}).  According to this principle, in a context in which individuals need to exert some physical effort, say in walking to a park --- they should be motivated to find the solution that minimizes how much effort required. Critically, Zipf argued this simple principle had explanatory power at the level of social groups. He suggested that this principle governs the behaviors of individuals, but with interaction, this principle leads to an equilibrium in behavior at the level of the group.

This simple theory of behavior provides a parsimonious account of a wide range of social phenomena. A particularly clear example is the organization of people into social  groups in physical space \cite{zipf1949human}.\footnote{A second, well-studied example is economics. At the the level of the individual, the consumer tries to minimize something of value, but in this case the valued commodity is money, rather than energy (though these are arguably related in important ways). This is the study of microeconomics. With interaction among consumers, this single force leads to regularities at the level of the social group, or the economy--- the study of macroeconomics.} Zipf assumes that every individual in a society is both a consumer and producer of goods. Governed by the Principle of Least Effort, the individual should minimize effort in terms of movement across land, by consuming (i.e.\ living) and producing (i.e.\ working) at the same location. However, as the number of raw goods increases this becomes increasingly difficult because the consumer cannot not live at the doorstop of every finishing plant. This creates a conflict. On the one hand there is a force to diversify, so that the population lives at the doorstep of the production line. This creates a force for many separated communities in space, each producing a single good, but with little trade between other communities. On the other hand, there is force to unify so that it is easier to trade final goods. The result is an equilibrium where people live in many different urban centers across the land. This general theory is reflected in more modern theories of urban spatial layouts \cite{mills1967aggregative, brueckner1987structure}.

Importantly, Zipf's principle does not provide a description of how individuals come to solve pure coordination problems like the vacationer example above. In that case, it is not clear how two individuals with the exact same payoff structure would arrive at the same, otherwise arbitrary solution. To address this issue, we need the idea of {\it convention} which will return to in Part II. However, Zipf's principle does provide insight into how a single psychological force, shared by all individuals, can lead to biases for different alternatives (e.g., a preference for the shortest path to a location). When individuals with these same biases interact with each other, we see the emergence of an equilibrium. 

\subsection{Language use as a coordination problem}
The coordination  framework can be straight-forwardly applied to language use \cite{lewis1969convention}. Language use is a paradigmatic case of a coordination problem because it is a tool that is universal in a community, easy to use, and capable of expressing complex ideas. In the case of language, the core of the coordination problem lies in the resolution of reference. Broadly, resolving reference requires interpreting a meaning from some utterance. At the level of individual lexical items, this is a difficult problem because the relationship between linguistic form and meaning is arbitrary \cite{saussure, hockett1960}. That is, knowing the form of a word does not give a language user any insight into the meaning of that word. Consequently, there is no inherent mapping between form and meaning and speakers must coordinate their behavior. 

\begin{table}[t]
\begin{center}
\begin{tabular}{l p{3cm} l p{3cm} l p{3cm} l}
 &  & \multicolumn{2}{c}{Speaker 1} \\ \cline{2-4} 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{``fep"} & \multicolumn{1}{l|}{``dax"} \\ \cline{2-4} 
\multicolumn{1}{c|}{\multirow{2}{*}{Speaker 2}} & \multicolumn{1}{l|}{Object A} & \multicolumn{1}{l|}{0,0} & \multicolumn{1}{l|}{1,1} \\ \cline{2-4} 
\multicolumn{1}{c|}{} & \multicolumn{1}{l|}{Object B} & \multicolumn{1}{l|}{1,1} & \multicolumn{1}{l|}{0,0} \\ \cline{2-4} 
\end{tabular}
\caption{A payoff matrix of the mapping problem. Given two words and two referents, the mappings are arbitrary. The only constraint is that no word should map to more than one object, and no object should map to more than one word. Thus, as in the vacationer example, speakers must coordinate.}
\end{center}
\end{table}

The arbitrariness of linguistic form leads to a formal equivalence between the problem of reference and the problems of coordination described above.  To understand this similarity, consider  a case where  there are two novel words, ``dax" and ``fep," and two novel objects, Object A and Object B. Given this information alone, the listener has no a priori insight into which object each word refers to. This is a problem because the two interlocutors must somehow arrive at the same mappings between words and referents in order to communicate (a system in which you call Object A ``fep" and I call it ``dax" is a terrible communication system). The interlocutors must therefore coordinate. 

The payoff structure for this problem is identical to the vacationer example above (Table 3). Because language is arbitrary, neither speaker cares whether you call Object A ``fep" or ``dax;" they only care that their mappings are the same.  These general dynamics are true not only of individual lexical items, but of all cases of reference. Consider again our example of the barista and the customer. In interpreting the phrase, ``Room for cream?," the individual lexical items are relatively unambiguous --- presumably both know what ``room" and ``cream" mean. But, the intended meaning of the entire phrase is underspecified, and so the interlocutors must work together to resolve meaning.

In this framework, we can think of {\it pragmatics} as the study of the psychological processes that lead to an equilibrium in these referential coordination problems. Pragmatics, then, is just a specific case of the dynamics described by \citeA{zipf1949human}. In the case of language, Zipf's insight was that speech could be thought of as its own economy, similar to any other social system. Speech has a physical cost and could be used as tool. He suggested the speaker and the listener were both governed by the Principle of Least Effort and this lead to an equilibrium. In the case of the speaker, effort could be minimized if there existed a single word {\it w} that could be used to refer to the set of all concepts {\it C}. In the case of the listener, effort would be minimized (in terms of understanding) if there existed a unique word for each  unique concept {\it c}. The dynamics of the interaction of these two opposing forces is pragmatics. 
%synthesis of two antitheses (horn, 22)
Many theorists have tried to account for pragmatic regularities in behavior, most notably \citeA{grice1975logic}. However, \citeA{horn1984} presents a particularly parsimonious theory that closely aligns with Zipf's more general formulation. He posited two principles that describe the manifestation of Zipf's Principle of Least Effort for the speaker and the hearer each. 
\begin{quote} \textsc{speaker}: Say no more than you must. ({\it Principle of Necessity}) \end{quote}
\begin{quote} \textsc{hearer}: Say as much as you can. ({\it Principle of Sufficiency})\footnote{Horn refers to these as the {\it R} and {\it Q} principles, respectively. I've opted  for less opaque terminology.} \end{quote}
These principles are quite straight forward. As a speaker with a necessary meaning to contribute, you want to say a little as possible, while still conveying the intended meaning. In contrast, as a listener, you want the speaker to say as much as possible to minimize your effort at arriving at the correct interpretation. That is, you want the speaker to use sufficient language. In the limit, each strategy on its own does not result in a successful communication system. This is because the speaker's and the hearer's goal are fundamentally linked: While in the short term, in might be less effort for the speaker to utter a single sound, ``blah," to convey her meaning, this will lead to confusion on the part of the hearer, which the speaker will then have to clarify with additional language. The speaker and hearer must therefore resolve their two opposing forces  in what Horn called a ``division of pragmatic labor"  in order to arrive at an equilibrium point \cite[p. 22]{horn1984}.\footnote{Note that there is a super maxim that is also operating here: the cooperative principle \cite{horn1984, grice1975logic}. The cooperative principle is essentially the idea that the interlocutors realize that utterances are the result of an equilibrium from the dynamics these two forces. Put another way, it is a statement that the interlocutors realize that they are playing a coordination game.}

\begin{figure}
\begin{center} 
\includegraphics[width=3in]{figs/frank2012.png}
\caption{\label{fig:frank2012}  Example stimuli from Frank and Goodman (2012). In this case, the intended referent is the middle shape. Both speaker and hearer agree that utterance ``circle" is  an equilibrium point, as compared to ``blue," even though both terms equally describe the intended referent in truth-functional terms.}
\end{center} 
\end{figure}

While these principles are simple, the dynamics they give rise to are complex. \citeA{frank2012predicting} present a formal model that captures these dynamics in a simple reference game. In their game, there are three possible referents and each referent has two relevant features (Fig.\ 1). Given the constraint that a speaker can only utter a single word, there are always two possible words the speaker could utter. For example, if the  intended referent is a blue circle, a speaker could use either the word ``blue" or ``circle" to refer to the object. Critically, both words are equally true of the referent from the perspective of truth functional semantics. The phenomenon that this model captures is that the speakers use different words to refer to an object --- and that listeners expect them to --- depending on the context in which the word is uttered. In particular, speakers  tend to choose a word that most uniquely identifies the intended referent, given the referential context. In other words, they select the word that is most informative. For example, in the example trial pictured in Figure 1, speakers tend to use the word ``circle" instead of ``blue'' to identify the middle referent.  Frank and Goodman use a Bayesian framework to formalize this notion of informativity, and their model closely captures the behavioral data in this reference game. This suggests that the behavior of both interlocutors is guided by a tacit understanding of informativity in the referential context. 

This notion of informativity falls directly out of Horn's principles. In this reference game, speakers are constrained by the length of the utterance they can use (one word), but the choice of words is free. From the listener's perspective, the utterance must be sufficient and so uttering ``blue" would be insufficient in the above context because it is ambiguous, and there is a better alternative. From the speaker's perspective, the utterance must be necessary, but should not be too verbose. This force is enforced by structure of the task --- the speaker must contribute something to participate in the task, and the utterance cannot be overly verbose given the single word constraint. Maximal informativity --- a sufficient contribution, given the context --- is thus the equilibrium between these two forces.

\subsection{Pragmatic equilibria reflected in the structure of language}

Simple reference games like that of \citeA{frank2012predicting} are one example of the kind of equilibria that emerges from the interaction of Horn's principles, but there are many others. In the present section, we consider how these  pragmatic equilibria points in language use are reflected in the structure of language. We will consider this relationship for three different kinds of linguistic structure: semantics, words, and syntax.

\subsubsection{Semantics}
Semantics concerns the context-independent meaning associated with a word. The size of the semantic space denoted by particular word reflects an equilibrium point between Horn's speaker and hearer principles.  From the hearer's perspective, Horn argues there is a pressure  to narrow semantic space \cite{horn1984}. This reflects the idea that the hearer's optimal language is one in which every possible meaning receives its own word. One example of this is the word ``rectangle." This word refers to a quadrilateral with four right angles. A special case of a ``rectangle"  is a case where the four sides are equal in length, which has its own special name, ``square." Consequently, the term ``rectangle" has been narrowed to mean a quadrilateral with four right angles, where the four sides are {\it not} equal.\footnote{Horn also points out that there are cases of narrowing that are speaker-based, as in ``drink" for ``alcoholic drink."} From the speaker's perspective, there is a pressure for semantic broadening. This is because the speaker's ideal language is one in which a single word can refer to a wide range of meanings. An example of this is the broadening of brand names to refer to a kind of product. For example, ``kleenex" is a name of a product name for facial tissues, but has taken on the meaning of facial tissues more generally.

The opposition of these two semantic forces predicts an equilibrium in the organization of semantic space that satisfies the pressures of both speaker and hearer. A body of empirical work has tested this prediction by examining the organization of particular semantic domains cross-linguistically \cite{regierword}. Languages show a large degree of similarity in how they partition semantic space for a particular domain, which is likely due to universal cognitive constraints. But, they also show a large degree of variability and these different systems can be shown to all approximate an equilibrium point between speaker and hearer pressures. 

 \citeA{kemp2012kinship} demonstrate this systematicity in the semantic domain of kinship. For each language, they developed a metric of the degree to which  Horn's speaker and hearer pressures (in their terminology: communicative cost and complexity, respectively) are satisfied. A language that better satisfies the hearer's pressure is one that is more complex, as measured by the length of the description of the system in their representational language. A language that better satisfies the speaker's pressure is one that requires less language to describe the intended referent. To understand this, consider the word ``grandmother" in English: this word is ambiguous in English because it could refer to either the maternal or paternal mother, and so referring to one in particular is more costly in English than in a language that encodes this distinction lexically. They find that the set of attested languages is a subset of the range of possible languages, and this subset partition the  semantic space in a way that is near the optimal tradeoff between speaker and hearer pressures (Fig.\ 2). This type of analysis has also been done for the domains of color \cite{regier2007color}, light \cite{baddeley2009relationship}, and numerosity \cite{xu4numeral}.
 
 \begin{figure}
\begin{center} 
\includegraphics[width=2in]{figs/kemp2012.pdf}
\caption{\label{fig:frank2012} Plot  from Kemp and Regier (2012). Languages organize the semantic space of kinship in a way that optimizes both speaker and hearer pressures. The notion of {\it communicative cost} maps onto Horn's speaker principle and the notion of {\it complexity} maps onto Horn's hearer principle. Gray circles represent possible systems and black circles represented actually attested languages. The key observation is that all of the attested languages are clustered around the bottom left corner that corresponds to an equilibrium between speaker and hearer pressures.} 
\end{center} 
\end{figure}

A second phenomenon that is predicted by these forces is the presence of lexical ambiguity. That is, cases in which there are multiple meanings associated with a word, from a context-independent perspective. Language is rampant with examples. For example, the word ``bat" could mean either the instrument used in baseball or the flying mammal. This type of ambiguity in context-independent meaning is tolerated because the meaning is usually easily disambiguated by context. When the word ``bat" is uttered while watching a baseball game,  the mammal usage of the word is very unlikely. We can view the presence of this ambiguity as an equilibrium in Horn's speaker and hearer principles. If the meaning of a word can be disambiguated by the referential context, then it would violate the speaker's principle to have an overly-specific term for a meaning. 

Indeed, recent work by \citeA{piantadosi2011b} reveals systematicity in the presence of lexical ambiguity in language. They argue that ambiguity results from a speaker based pressure to broaden the meaning of a word to include multiple possible meanings. In particular, they suggest that this pressure should lead to a systematic relationship between the presence of ambiguity and the cost of a word. According to their argument, costly words (in terms of length, frequency, or any metric of cost) that are easily understood by context violate the speaker's principle to say no more than you must. Consequently, there should be a pressure for these meanings to get mapped on to a different, less costly word. This word may happen to already have a meaning associated with it, and so the result  is multiple meanings being mapped to a single word. For example, in the case of the word ``bat," a speaker could instead say ``baseball bat," but because this referent is easily disambiguated in context from the mammalian meaning,  Horn's speaker principles leads to a pressure to use the shorter form.\footnote{There are also cases of temporary ambiguity in the meanings of syntactic structures. For example, in a sentence that begins ``The coach knew you..." it is unclear whether ``you" is a direct object or the subject of a relative clause. Speakers can avoid this ambiguity by inserting a ``that," but this is optional. Work by \citeA{ferreira2000effect} suggests that speakers often do not avoid this ambiguity, presumably because the intended meaning can easily be recovered from context.} This leads to a testable prediction that shorter words should tend to be more ambiguous.  Through corpus analyses, \citeA{piantadosi2011b} find this precise  relationship between cost and ambiguity. They find a linear relationship between word length and ambiguity across English, Dutch and German: Shorter words are more likely to have multiple meanings. 

An additional case of this lexical ambiguity is found in words that have very little context-independent meaning, known as indexicals or deictics \cite{frawley2003international}. These words get their meaning from the particular referential context of the utterance, and are therefore highly ambiguous from a context-independent perspective. There are many types of indexicals that are present to varying degrees across languages. An example of a temporal indexical form is ``tomorrow." The context-independent meaning of this word is something like ``the day after the day this word is being uttered in.'' Critically, abstracted from any context, this word has little meaning; it is impossible to interpret without having knowledge about the day the word was uttered. This phenomenon is also present in person pronouns (e.g.\ ``you" and ``I") and spatial forms, like ``here" and ``there."  As for lexical ambiguity, this type of ambiguity is a predicted equilibrium point from Horn's principles: If the hearer can recover the intended referent from context, the speaker would be saying more than is necessary by using an overly-specific referential term (e.g., ``December 18th, 2014" vs.``tomorrow"). Language structure reflects this pressure through lexicalized ambiguity in the form of indexicals.

\begin{figure}
\begin{center} 
\includegraphics[width=3in]{figs/onetoone.pdf}
\caption{\label{fig:frank2012} Three possible structures on the organization of lexicon. According to Horn's principles, the hearer's optimal language is one in which there is a one-to-one mapping between words and concepts. The speaker's optimal language is one in which there is one word that maps to many concepts. Synonymy, or a many-1 structure, is thus dispreferred by both interlocutors.}
\end{center} 
\end{figure}

Finally, the relationship between the meanings of different words can be seen as a consequence of Horn's principles. A number of theorists have noted a bias against two words mapping onto the same meaning --- that is, a bias against synonymy \cite{saussure, kiparsky1983word, horn1984, clark1987principle, clark1988logic}. This bias is an equilibrium between Horn's speaker and hearer principles. Recall that the optimal language for a hearer is one in which each meaning maps to its own word --- exactly a language biased against synonymy (see Fig. 3). It turns out that the speaker's pressure also biases against synonymy.  The optimal language for the speaker is a language where a single word maps to all meanings. But, a case where multiple words map to a single meaning is also undesirable because the speaker must keep track of two words. So, for both the speaker and the hearer, there is pressure to avoid synonymy. Thus, when a listener hears a speaker use a second word for an existing meaning, the hearer infers that this could not be what the speaker intended because this would violate the speaker's principle. The result is an assumption that the second word maps to a different meaning. This pattern is reflected in language structure by a one-to-one pattern in the lexicon --- that is, a structure in which each word maps to exactly one meaning and each meaning maps to exactly one word.

As one kind of evidence for this one-to-one structure in the lexicon, \citeA{horn1984} points to a phenomenon called {\it blocking}. Blocking refers to cases in which an existing lexical form blocks the presence of a different, derived form with the same root. Horn  points to the following examples:
 \begin{quote} 
 	(a) fury furious *furiosity\\
	(b) *cury curious curiosity 
\end{quote}
In both (a) and (b), forms that would be expected, given the inflectional morphology in English, are not permitted. This is presumably because they would have the same meaning as the existing form because they have the same root. Examples such as this provide some evidence for a one-to-one structure in language, but a one-to-one structure is a particularly difficult linguistic regularity to test empirically. Nonetheless, it is an important regularity because it licenses certain inferences in interpreting the meaning of words. In particular, the cognitive representation of a one-to-one regularity has been posited as an explanation of children's bias to map a novel word onto a novel object \cite{markman1988, markman2003}. We return to this issue in Part II.

\subsubsection{Words}
Horn's principles make an interesting prediction about the length utterances and their meanings. In many cases, it is possible to use two different utterances to refer to the same meaning (in truth functional terms), and often these utterances differ in length. \citeA{horn1984} presents the following example: 
\begin{quote} 
 	(1a) Lee stopped the car.\\
	(1b) Lee got the car to stop.
	
	%(2a) Black Bart killed the sherif.\\
	%(2b) Black Bart caused the sherif to die.
\end{quote}
Both (a) and (b) have the same denotational meaning (the successful stopping of a car), but they differ in length ((b) has two extra words). Horn argues that this asymmetry leads to an inference on the part of the listener that the two differ in meaning. The logic of this inference is  identical to the lexical structure case above. The listener hears a speaker use a more costly phrase to express a meaning that could have been expressed in a less costly way. The listener thus infers that this other meaning could not be what the speaker intended because this would violate the speaker's principle to say no more than is necessary. Horn adds an additional layer to this argument. He suggests that no only do these two forms differ in meaning, but that they map onto meanings in a systematic way. In particular, he argues that the longer form gets mapped on to the more marked meaning, while the shorter form refers to the unmarked meaning.  The notion of `markedness' is underspecified here, but an intuitive definition is related to complexity: more marked things are more conceptually complex, while less marked things are more conceptual simple.  Thus, in the above example, (a) would refer to a simple, average case of a car stopping, while (b) might refer to case where something complex or unusual happened, perhaps Lee had to use the emergency brake.

%\begin{table}[t]
%\begin{center}
%\begin{tabular}{l p{3cm} l p{3cm} l p{3cm} l}
% &  & \multicolumn{2}{c}{Speaker} \\ \cline{2-4} 
%\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\[ 
%\left \{
%  \begin{tabular}{ccc}
%  short--simple \\
%  long--complex
%  \end{tabular}
%\right \}
%\]} & \multicolumn{1}{l|}{\(
%\left \{
%  \begin{tabular}{ccc}
%  short--complex \\
%  long--simple 
%  \end{tabular}
%\right \}
%\)} \\ \cline{2-4} 
%\multicolumn{1}{c|}{\multirow{2}{*}{Listener}} & \multicolumn{1}{l|}{\[ 
%\left \{
%  \begin{tabular}{ccc}
%  short--simple \\
%  long--complex
%  \end{tabular}
%\right \}
%\]} & \multicolumn{1}{l|}{0,0} & \multicolumn{1}{l|}{1,1} \\ \cline{2-4} 
%\multicolumn{1}{c|}{} & \multicolumn{1}{l|}{\[ 
%\left \{
%  \begin{tabular}{ccc}
%  short--complex \\
%  long--simple 
%  \end{tabular}
%\right \}
%\]} & \multicolumn{1}{l|}{1,1} & \multicolumn{1}{l|}{0,0} \\ \cline{2-4} 
%\end{tabular}
%\caption{Two equilibria points }
%\end{center}
%\end{table}

The source of the particular mapping between forms of different lengths and meanings of different degrees of markedness is unclear. This is because, in principle, there are multiple equilibrium points in the mapping between form and meaning. Assuming a one-to-one constraint on the mapping, there are two possible equilibria: \{short--simple, long--complex\} or \{short--complex, long--simple\} (Table 4). Both satisfy the constraint that each  form gets mapped to a unique meaning. So how do speakers arrive at the  \{short--simple, long--complex\}? This is a difficult result to derive from models of pragmatic reasoning. \citeA{bergen2014} successfully derive this result as a consequence of the fact that \{short--simple, long--complex\} is a more optimal mapping for the speaker (the indirect result of Zipf's Principle of Least Effort). Another possibility relies on iconicity: hearers have a cognitive bias to map more complex sounding forms to meanings that are similarly complex. 

Despite the absence of clear theoretical account of this phenomenon, the empirical data suggest that learners do indeed arrive at the predicted equilibrium. \citeA{bergen2012} provide evidence for this type of implicature in a learning game.  In their task, partners were told that they are in an alien world with three objects and three possible utterances of different monetary costs. They operationalize the idea of markedness or complexity as frequency, such that participants were instructed that each of the three different objects had three difference base rate frequencies  associated with them.  Participants' task was to communicate about one of the objects using one of the available utterances. If they successfully communicated, they received a reward. The results suggest that both the speaker and hearer expected costlier forms to refer to less frequent meanings. This study provides one of the piece of empirical work suggesting that Horn's predicted equilibrium between word length and meaning emerges in coordination games.  

There is a growing body of evidence suggesting this equilibrium is also reflected in the structure of words. One approach to testing this hypothesis is to use the linguistic context of a word to measure the complexity of meaning. The idea is that words that are highly predictable, given the linguistic context, have more complex meanings, while words that are less predictable given the linguistic context, have less complex meanings. \citeA{piantadosi2011a} measured the  the relationship between the predictability of words in context and the length of words. Across 10 languages, these two measures were highly correlated: words that were longer were less predictable in their linguistic context on average. This result held true even control for the frequency of words. Additional evidence for this relationship comes from examining pairs of words that  have  very similar meanings, but differ in length \cite<e.g. ``exam" vs.\ ``examination;">{mahowaldinfo}. Through corpus analyses, they find that the longer forms are used in less predicable linguistic contexts. In a behavioral experiment, they also find that  speakers are more likely to select the longer word in unsupportive contexts. This body of work points to a systematic relationship between word length and meaning, when complexity is operationalized as predictability in the linguistic context.

Some of our own work provides more direct evidence for this equilibrium. Given a novel word, we find that both adults and preschoolers are more likely to map a longer word to a more complex object, as compared to a short word \cite{lewis2014structure}. A key difference between our work from prior work is that we  directly manipulate the complexity of word meaning. We have operationalized complexity in three different ways. The first is to directly manipulate the number of object parts the referent has. Second, we have measured complexity by obtaining complexity norms from participants on real objects. Third, we have operationalized complexity through a reaction time measure. In each case, we see a bias to map longer words to more complex referents, as compared to a short word. We also find this bias in natural language. We asked participants to rate the complexity of the meaning  of 499 English words, and found that these ratings were highly correlated with word length in both English and 79 other languages. Taken together, this work provides strong evidence that the equilibrium between word length and complexity of meaning that is found in coordination games, such as \citeA{bergen2012}, is also reflected in the structure of the lexicon. 

\subsubsection{Syntax}
The order of words, or syntax, is another level of language structure that reflects equilibria of language use. \citeA{levinson2000presumptive} provides a detailed account of how Chomsky's syntactic binding constraints can be reinterpreted as pragmatic equilibria.

 Hopper and Thompson (1984) -- nouns and verbs come from discourse function

Several experimental findings  also  suggest that there are pragmatic equilibria reflected in syntax. One of the primary patterns of linguistic structure  to be explained is the linear structure of words. In particular, why some word orders are much more prevalent across languages than others. \citeA{gibson2013noisy} offer an account of one aspect of this regularity and this account can be interpreted as a suggestion that a pragmatic equilibrium is reflected in the structure of language. 

Their argument is as follows. There is some evidence that subject-object-verb (SOV) word order is the cognitive default \cite<e.g.>{senghas2004children}. This proposal reflects the fact that SOV order is the most prevalent word order cross-linguistically (47\%). But a puzzle still remains: If there is a SOV bias, why is a second order --- SVO --- almost equally as prevalent (41\%)? Gibson et al.\ (2013) propose that the move from an SOV to SVO word order reflects a communicative pressure. The idea is that subjects and objects are often semantically confusable (because they are both entities), and thus, it is possible in  the ``noisy channel" of communication for one of the noun phrases to get deleted. This leads to confusion on the part of the hearer. Thus, they argue that the two  should be linearly separated  with the verb argument in order to avoid confusion. This is advantageous because if an argument is deleted, the correct grammatical relation of the communicated argument can be inferred from the input in an SVO order, but not an SOV order. 

Though they motivate this prediction from an information theoretic perspective, this result can also be derived from Horn's principles. Both the hearer and the speaker want to minimize effort. If it is indeed the case that SOV order frequently leads to confusion on the part of the hearer, this becomes problematic for the speaker who will have to often expend extra effort to clarify the confusion. Thus, given that there is an alternative word order that requires the same amount of effort ---SVO order ---  there should be a pressure on the part of the speaker to move towards using this order.

To explore this proposal, Gibson et al.\ (2013) asked speakers to produce sentences describing scenes. A critical prediction of their argument is that confusion should be more likely when both arguments are animate (e.g.\ ``The girl pushed the boy") compared to a case when there is an asymmetry in animacy (e.g.\ ``The girl pushed the car"). In their key experiment, speakers of Japanese and Korean viewed brief videos of events. Japanese and Korean speakers were selected because their native languages were not SVO. Following each event, participants used non-verbal  gesture to represent the events. Critically, the events  involved three nouns that required using and embedded clause structure to describe.  The patient of the embedded clause was either animate or inanimate. The measure of interest was the location of the embedded as a function of the confusability of the  noun phrases. If participants gesture in accord with their native word order, they should show a SOV ($S_{1}\  [S_{2}\ O_{2}\ V_{2}]\  V_{1}$) pattern in their gestures. However, if this bias is sensitive to the confusability of  referents, they should be more likely to show a SVO pattern ($S_{1}\  V_{1\ }[S_{2}\ O_{2}\ V_{2}])$ when all the noun phrases are animate. Consistent with their prediction, this is exactly what they found: Japanese and Korean speakers were more likely to use the SVO pattern for the embedded events when the entities were all animate, as compared to when the object was inanimate.

Case marking is a second case in which pragmatic equilibria are reflected in syntax. In many languages, case marking is used as a syntactic strategy to indicate  grammatical relations, like subject or object. Case markers are affixes that attach to the noun root, and are typically used in languages where word order is not a cue to grammatical relations. Case marking is usually optional but principled in its usage based on semantic properties of the nouns like animacy. For example, speakers often case mark nouns that appear in unpredictable roles, such as when an inanimate noun functions as a subject. Following logic similar to  \citeA{gibson2013noisy},  \citeA{fedzechkina2012language} used an artificial learning paradigm to test whether speakers regularize a language to minimize confusion between nouns. They predicted that speakers should be more likely to use case marking when the nouns were all animate, and thus confusable. They exposed learners to a verb-final language with flexible constituent order and optional case-marking. Critically, case-marking in the input language was not conditioned on animacy. Consistent with the prediction, they found that learners tended to mark animate objects with an overt case marker more frequently than inanimate objects (because animate objects are confusable  with animate subjects). This provides another case in which pragmatic pressures are reflected in  regularities in language structure.

 
%%%%%%%%% PART II %%%%%%%%% 
\section{Part II: A casual link between linguistic use and linguistic structure}
Why does language structure reflect  patterns of language use? In the present section, I propose a speculative answer to this question. The answer  posits an indirect causal link between language use and language structure: Language use over time leads to regularities in linguistic structure. I will outline this answer by relying on an analysis of language separated by five different timescales. To preview, the hypothesis is that linguistic structure reflects language use as a consequence of local dynamics between adjacent timescales.

A {\it timescale} is a unit of time over which significant changes in state occur. For example, the timescale of dinner is about an hour, where the significant changes in state are walking to the restaurant, sitting down, ordering food, eating the meal, then dessert, etc. In contrast, the timescale of gaining weight occurs over weeks, where the significant changes in state correspond to appreciable weight changes. Critically, the length of the timescales is determined by the change of interest. 

\begin{figure}
\begin{center} 
\includegraphics[width=6in]{figs/timescales1}
\caption{The five linguistic timescales. Each timescale is nested within a slice of longer timescales. The claim is that the dynamics between adjacent timescales (e.g., pragmatic and discourse) lead to changes over time in longer timescales. The developmental timescale is characterized by a particular person from a particular generation, $p_A$, interacting with series of people over the lifespan. Repeated interactions with the same person, $p_B$, characterize the discourse timescale.}
\end{center} 
\end{figure}

In the case of language,  there are five timescales over which significant changes occur (Fig. 4). The first is the {\it pragmatic timescale}. The pragmatic timescale corresponds to the processes described by Horn's principles, and addressed in detail in Part I. The {\it discourse timescale} is a slightly longer timescale. The discourse timescale corresponds to repeated interactions with the same person; a series pragmatic interactions. The third is the {\it developmental timescale}. The developmental timescale corresponds to the lifetime of an individual. It is composed of many interactions (on the pragmatic timescale), some of which with the same people (on the discourse timescale).  Many people interacting over their lifetimes lead to change at the {\it cultural timescale}. This is the timescale over which significant changes in language structure  occur (sometimes referred to as the ``language change" timescale). Finally, at the longest timescale, is the {\it evolution timescale}. All of the dynamics at lower timescales occur within a small slice in evolutionary time. While I will not have much to say about this timescale, its main significance is to situate the present claims with respect to claims about the innateness of language. Following \citeA{christiansen2008}, the suggestion is that there are aspects of language that are innate and constrain the dynamics of shorter timescales. Importantly, however, there are also important dynamics that take place at  shorter timescales, and these dynamics are the focus of the present section.



The phenomenon to be explained is why dynamics at the pragmatic timescale are reflected in structure at the cultural timescale. The proposal is that there are dynamics between adjacent timescales, and that, over time, these dynamics lead to change on longer timescales. Importantly, the character and phenomena of the dynamics between each pair of timescales are different. For example,  the dynamics between discourse and developmental timescales are reflected in cognitive changes in the mind of a particular speaker. In contrast, the dynamics between cultural and evolutionary timescales are reflected in genetic changes in linguistic abilities.

The idea of a causal relationship between language use and structure is not new. One of the earliest proposals of this idea was \citeA{whorf1956language} who argued that habitual patterns of talking in particular ways (what he called ``fashions of speaking") lead over time to different conceptualizations of of the world.\footnote{I think this is an important nuance to claims about linguistic relativity that is often over-looked: It is not {\it that} a language has a label for a concept that matters,  but rather the presence of that label in conjunction with a developmental history of using that label.} Grammar is a case where this view as been particularly well articulated, under the heading of {\it Emergent Grammar} \cite{hopper1987emergent}: 

\begin{quote} The notion of Emergent Grammar is meant to suggest that structure, or regularity, comes out of discourse and is shaped by discourse as much as it shapes discourse in an on-going process. [...] Structure, then, in this view is not an overarching set of abstract principles, but more a question of a spreading of systematicity from individual words, phrases and small sets. (p. 142)
\end{quote}
More recently, cognitive psychologists has begun to formally model these dynamics. In this tradition, \citeA{bybee2005alternatives} write: ``Properties of formal structure [...] are facts about the structure that are to be explained as arising from the cumulative impact of the processes that shape each language, as it adapts through the process of language use" (p. 406). They argue for the value of a connectionist framework in capturing these dynamics. Also within a  connectionist framework, \citeA{mcmurray2012} highlight the relevance of different timescales in capturing the phenomenon of children's word learning across the developmental timescale. Perhaps the broadest framing of these dynamics has been by \citeA{christiansen2008}, who put forth an argument closely aligned with the present argument.

The goal of the present section is to synthesize these many claims about cumulative dynamics into a single framework. In what follows, I describe cognitive phenomena related to the dynamics between each pair of adjacent timescales, beginning with the two shortest timescales: pragmatics and discourse. 

%%% Prag and discourse %% 
\subsection{Dynamics between pragmatic and discourse timescales} 
The dynamics between pragmatics and discourse are critical to understanding how interlocutors solve the problem of multiple equilibria. Recall coordination problems like the one described in the payoff matrix in Table 3. The critical feature of this coordination problem is that there are two equally good equilibrium points. The question then is, how do speakers mutually arrive at the same point? \citeA{lewis1969convention} proposes the notion of {\it convention} to answer this question. He suggests that once speakers happen to successfully coordinate their behavior at a particular equilibrium, there is inertia to maintain that equilibrium rather than switch to an alternative which is, a priori, equally good. That is, a series of  interactions over the pragmatic timescale lead to a convention at the discourse timescale. In the case of this example, this idea is that neither ``dax" nor ``fep" is a better name for object A. But, once the speakers successfully coordinate by using ``dax" to refer to object A, there is a pressure for both to continue using this linguistic form to refer to object A. The speakers have thus established a convention. The more this convention is used, the more entrenched it becomes.

In the social psychology literature, there is a large body of work that speaks to the psychological processes that support this behavior. This work is under the the rubric of ``conformity," where the idea is that individuals in social groups are motivated to conform to the perceived social norm  \cite{cialdini2004social}. When language use is couched as a particular case of social interaction, this work becomes relevant. The idea is that all mappings between linguistic form and meaning are arbitrary, but once established, speakers are motivated to adhere to the perceived norm (that ``dax" maps to object A, for example).  Sherif's autokinetic experiment (1935)\nocite{sherif1935} provides a powerful demonstration of this pressure. In his task, participants viewed a dot of light on a wall and were asked to indicate when the dot moved and then estimate its distance. In reality, the light never moved. Nonetheless, all individuals reported seeing some movement in the light. Critically, in one version of the study, three strangers  were tested individually in the task. They were then tested as a group three additional times. The group context was identical to the individual context except that the subjects could overhear other subjects' responses. Figure 5a plots the median distance judgements of one group of three subjects over iterations of the experiment. When tested individually, the three subjects were highly variable in their distance judgements. However, when tested together, their judgements tended to converge, and this convergence increased over iterations of the experiment. This result provides a clear demonstration of the minimal conditions necessary for interacting social partners to converge on an arbitrary equilibrium. 

\begin{figure}
\begin{center} 
\includegraphics[width=5in]{figs/coordinatingmeaning.png}
\caption{\label{fig:results}  Plots reproduced from (a) Sherif (1935) and (b) Kirby,  Cornish, and Smith (2008). Plot (a) shows the median distance judgement (in inches) for three different subjects. The {\it x}-axis corresponds to four different iterations of the experiment: first individually, then three iterations as a group. Over time, the participants converge on an arbitrary norm.  Plot (b) shows the emergence of systematicity in the language across generations in the labeling task. Each line corresponds to a different set of people. Both plots suggest the emergence of systematicity, or conformity, within the group as a function of time. }
\end{center} 
\end{figure}

In the domain of language, this same phenomenon is observed in the way partners establish reference. Because there are multiple ways to refer to an object, interlocutors must establish some convention. This happens over the discourse timescale. \citeA{clark1986referring} demonstrate this phenomenon in the laboratory. In their task, pairs of naive subjects were randomly assigned to either the role of director or matcher. They were seated across from each other with an opaque wall  between them. Each subject had a set of cards with ambiguous images (identical to their partner's). The director's cards were arranged in a grid, and her task was to direct the matcher to organize her cards in the same way using only verbal instruction. After repeatedly completing this task with the same partner, the directors began to use overall fewer words to describe the cards over successive trials. For example, in trial one, one director used the phrase ``the next one looks like a person who's ice skating, except they're sticking their arms out in front," but by trial six the same director simply used the phrase ``the ice skater" to refer to that same card. This suggests that the interlocutors arrive at an equilibrium point about how to refer to the different referents, known as {\it lexical entrainment}. \citeA{brennan1996conceptual} argue that this shared way of referring to an object reflects a {\it conceptual pact} between interlocutors about how to conceptualize the referents. Consistent with this view, \citeA{metzing2003conceptual} show that this phenomenon is partner-specific, suggesting that low level cognitive effects (e.g.\ memory recency) cannot alone account for the observed coordination. Together, this line of work demonstrates how in-the-moment pragmatic pressures lead to equilibrium in discourse.

In addition to reference, there are a number of findings that suggest that interlocutors coordinate other aspects of language.  For example, in a study by \citeA{branigan2000syntactic}, interlocutors were found to coordinate their syntactic structures. The task involved completing a picture description task with a confederate in which the two alternated speaking. Critically,  sometimes the confederate used a prepositional object structure (e.g.\ ``The girl is throwing the ball to the dog.") and sometimes she used a double-object construction (e.g.\ ``The girl is throwing the dog the ball.").  Subjects tended to use the syntactic structure used by the confederate to describe their own picture (even though there was no semantic overlap between the two), suggesting a coordination of syntactic structure. Other work suggests low level perceptual coordination. For example,  \citeA{trude2012talker} find that speakers acquire speaker-specific knowledge about how individuals pronounce different words. While the cognitive mechanism supporting these different types of coordination may differ,  each is a case of discourse-level coordination in language use. 

%%% Discourse and development %% 
\subsection{Dynamics between discourse and developmental timescales} 
Many repeated interactions on the pragmatic and discourse timescale lead to change on the developmental timescale. One way to think about this change is as {\it learning}. There are a wide range of forms this learning could take, however. One possibility is that this learning is a sort of ``cached equilibrium" that results from aggregating over many instances of the different social partners that arrive at the same linguistic equilibrium.

This process has been well-studied in the case of learning the meaning of new words. There is a growing body of evidence to suggest that children can make use of pragmatic information in learning the meanings of novel words.
%Frank - Inferring word meaning by assuming speakers are informative
%Alis adjective paper
%\cite{xu2007}
%principle of contrast  
%\cite{smith2013learning}
\cite{chater2010language}

But this in-the-moment inference is not itself learning. Learning, rather, is result of storing information about these individuals interactions  and doing some sort of generalization across them. There is growing evidence that the in-the-moment inference and learning are two distinct cognitive processes. 
% ricardo's work
% mcmurray

Hierarchical Bayesian models provide an appealing way to think about this generalization process,  because they demonstrate how learners can quickly go from variable instances of language use to the induction of some sort of regularity. In short, the provide a demonstration of how learners can go from token to type. 
%smith paper, 
%kemp learning to learn


%%% Development and language %% 
\subsection{Dynamics between developmental and cultural timescales}
One possible route to the emergence of structure on the cultural timescale is aggregating over learning.
martin nowak,  michelle, liberman, pinker (nature, 2007) -  relationhip between rules and frequency of irr (quantifiying the evolutionary dynamics of language)
pierrehumbert 2001- argument about frequency

- christiasen and chater
\cite{smith2013learning}
\cite{fedzechkina2012language}

\begin{figure}
\begin{center} 
\includegraphics[width=6in]{figs/timescales2}
\caption{}
\end{center} 
\end{figure}

Recent work using an artificial language paradigm tests this prediction. In a study by \citeA{kirby2008cumulative}, participants were presented with a novel language and asked to learn the pairings between words to novel images. For the first subject, the mappings between words and images was randomly generated. In the training phase, the subject was presented with an image and a label for that image. In the testing phase, they were shown a new image and asked to guess what word they thought was associated with that image. This first subject's responses were recorded, then divided into half (one half for training and one half for testing), and presented to a subsequent subject. This process repeated for a total of 10 subjects. Consistent with the Sherif (1935) results, it was predicted that language use would become more systematic over time. In particular, it was predicted that a pattern should emerge in the mapping between features of the stimuli (e.g.\ color, shape, etc.) and syllables in the novel words. This is exactly what was found (Figure 1b). As the number of generations increased, the language became more systematic. This pattern was observed across a four different ``strings" of participants.





 \subsection{An empirical challenge: Sufficient but not necessary mechanisms}
Parallels between development and language structure, and development and pragmatics in the moment of language use - ontological status of regularities just because they exist doesn't' mean we represent them. ontological status of these regularities -- difference between this and other laws of nature (e.g. physics) is that we can represent them -- general abstract rules (connect to symbol literature). The question is: do we represent these regularities explicitly? (unlike macroeconomics) Just because we behave in away that is constant with macro economics, doesn't mean we = represent the regularity.
\cite{posner and keele 1968} -- specific and general information used

This issue is particular clear in the case of the one-to-one equilibrium in the structure of the lexicon. A one-to-one I\cite{lewis2013b}

\section{Conclusion}
"diachronic perspective"
What this is not -- totally reductionist to pragmatis. As christiansen and CHater argue, multiple factors (most notable things like memory).
What is the alternative theory -- all theories of language echange must make reference to individual. ?
HBB's as tool

% TO DO:
- proof everything
- write levinson paragraph
- fix tables 
- fix preview paragraphs in intro

\bibliographystyle{apacite}
\bibliography{biblibrary}

\end{document}

